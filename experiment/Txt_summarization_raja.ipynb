{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pytorch::pytorch torchvision torchaudio -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print\n",
    "from pprint import pprint\n",
    "# Datasets load_dataset function\n",
    "from datasets import load_dataset\n",
    "# Transformers Autokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# Standard PyTorch DataLoader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import operator\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading is done!\n"
     ]
    }
   ],
   "source": [
    "hupd_dict = load_dataset('HUPD/hupd',\n",
    "    name='sample',\n",
    "    data_files=\"https://huggingface.co/datasets/HUPD/hupd/blob/main/hupd_metadata_2022-02-22.feather\",\n",
    "    icpr_label=None,\n",
    "    train_filing_start_date='2016-01-01',\n",
    "    train_filing_end_date='2016-01-21',\n",
    "    val_filing_start_date='2016-01-22',\n",
    "    val_filing_end_date='2016-01-31',\n",
    ")\n",
    "\n",
    "print('Loading is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_claims = []\n",
    "for i in range(hupd_dict['train'].shape[0]):\n",
    "    claims_text = hupd_dict['train'][i]['claims']\n",
    "    all_claims.append(claims_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = set(stopwords.words('english'))\n",
    "wordlemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "please change the index here:\n",
    "- example_index and org_claim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating summaries\n",
    "# example_index = 5  # Change this to any index you want to summarize\n",
    "# example_text = all_claims[example_index]\n",
    "dirty_claim = hupd_dict['train'][1]['claims'] # Change this to any index you want to summarize same with \"example_index\"\n",
    "# print(\"Original claim:\\n\", dirty_claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF readymade extractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(words):\n",
    "    lemmatized_words = []\n",
    "    for word in words:\n",
    "       lemmatized_words.append(wordlemmatizer.lemmatize(word))\n",
    "    return lemmatized_words\n",
    "def stem_words(words):\n",
    "    stemmed_words = []\n",
    "    for word in words:\n",
    "       stemmed_words.append(stemmer.stem(word))\n",
    "    return stemmed_words\n",
    "def remove_special_characters(text):\n",
    "    regex = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(regex,'',text)\n",
    "    return text\n",
    "def freq(words):\n",
    "    words = [word.lower() for word in words]\n",
    "    dict_freq = {}\n",
    "    words_unique = []\n",
    "    for word in words:\n",
    "       if word not in words_unique:\n",
    "           words_unique.append(word)\n",
    "    for word in words_unique:\n",
    "       dict_freq[word] = words.count(word)\n",
    "    return dict_freq\n",
    "def pos_tagging(text):\n",
    "    pos_tag = nltk.pos_tag(text.split())\n",
    "    pos_tagged_noun_verb = []\n",
    "    for word,tag in pos_tag:\n",
    "        if tag == \"NN\" or tag == \"NNP\" or tag == \"NNS\" or tag == \"VB\" or tag == \"VBD\" or tag == \"VBG\" or tag == \"VBN\" or tag == \"VBP\" or tag == \"VBZ\":\n",
    "             pos_tagged_noun_verb.append(word)\n",
    "    return pos_tagged_noun_verb\n",
    "def tf_score(word,sentence):\n",
    "    freq_sum = 0\n",
    "    word_frequency_in_sentence = 0\n",
    "    len_sentence = len(sentence)\n",
    "    for word_in_sentence in sentence.split():\n",
    "        if word == word_in_sentence:\n",
    "            word_frequency_in_sentence = word_frequency_in_sentence + 1\n",
    "    tf =  word_frequency_in_sentence/ len_sentence\n",
    "    return tf\n",
    "def idf_score(no_of_sentences,word,sentences):\n",
    "    no_of_sentence_containing_word = 0\n",
    "    for sentence in sentences:\n",
    "        sentence = remove_special_characters(str(sentence))\n",
    "        sentence = re.sub(r'\\d+', '', sentence)\n",
    "        sentence = sentence.split()\n",
    "        sentence = [word for word in sentence if word.lower() not in Stopwords and len(word)>1]\n",
    "        sentence = [word.lower() for word in sentence]\n",
    "        sentence = [wordlemmatizer.lemmatize(word) for word in sentence]\n",
    "        if word in sentence:\n",
    "            no_of_sentence_containing_word = no_of_sentence_containing_word + 1\n",
    "    idf = math.log10(no_of_sentences/no_of_sentence_containing_word)\n",
    "    return idf\n",
    "def tf_idf_score(tf,idf):\n",
    "    return tf*idf\n",
    "def word_tfidf(dict_freq,word,sentences,sentence):\n",
    "    word_tfidf = []\n",
    "    tf = tf_score(word,sentence)\n",
    "    idf = idf_score(len(sentences),word,sentences)\n",
    "    tf_idf = tf_idf_score(tf,idf)\n",
    "    return tf_idf\n",
    "def sentence_importance(sentence,dict_freq,sentences):\n",
    "     sentence_score = 0\n",
    "     sentence = remove_special_characters(str(sentence)) \n",
    "     sentence = re.sub(r'\\d+', '', sentence)\n",
    "     pos_tagged_sentence = [] \n",
    "     no_of_sentences = len(sentences)\n",
    "     pos_tagged_sentence = pos_tagging(sentence)\n",
    "     for word in pos_tagged_sentence:\n",
    "          if word.lower() not in Stopwords and word not in Stopwords and len(word)>1: \n",
    "                word = word.lower()\n",
    "                word = wordlemmatizer.lemmatize(word)\n",
    "                sentence_score = sentence_score + word_tfidf(dict_freq,word,sentences,sentence)\n",
    "     return sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = sent_tokenize(dirty_claim)\n",
    "text = remove_special_characters(str(dirty_claim))\n",
    "text = re.sub(r'\\d+', '', dirty_claim)\n",
    "tokenized_words_with_stopwords = word_tokenize(dirty_claim)\n",
    "tokenized_words = [word for word in tokenized_words_with_stopwords if word not in Stopwords]\n",
    "tokenized_words = [word for word in tokenized_words if len(word) > 1]\n",
    "tokenized_words = [word.lower() for word in tokenized_words]\n",
    "tokenized_words = lemmatize_words(tokenized_words)\n",
    "word_freq = freq(tokenized_words)\n",
    "input_user = int(input('Percentage of information to retain(in percent):'))\n",
    "no_of_sentences = int((input_user * len(tokenized_sentence))/100)\n",
    "print(no_of_sentences)\n",
    "c = 1\n",
    "sentence_with_importance = {}\n",
    "for sent in tokenized_sentence:\n",
    "    sentenceimp = sentence_importance(sent,word_freq,tokenized_sentence)\n",
    "    sentence_with_importance[c] = sentenceimp\n",
    "    c = c+1\n",
    "sentence_with_importance = sorted(sentence_with_importance.items(), key=operator.itemgetter(1),reverse=True)\n",
    "cnt = 0\n",
    "summary = []\n",
    "sentence_no = []\n",
    "for word_prob in sentence_with_importance:\n",
    "    if cnt < no_of_sentences:\n",
    "        sentence_no.append(word_prob[0])\n",
    "        cnt = cnt+1\n",
    "    else:\n",
    "      break\n",
    "sentence_no.sort()\n",
    "cnt = 1\n",
    "for sentence in tokenized_sentence:\n",
    "    if cnt in sentence_no:\n",
    "       summary.append(sentence)\n",
    "    cnt = cnt+1\n",
    "summary = \" \".join(summary)\n",
    "print(\"\\n\")\n",
    "print(\"Summary:\")\n",
    "print(summary)\n",
    "outF = open('summary.txt',\"w\")\n",
    "outF.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Maths only calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference from : https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background\n",
    "\n",
    "TF-IDF is made up of two algorithms:\n",
    "- Term Frequency : how common a word is\n",
    "    - calculation: </br>\n",
    "    <code> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document) </code>\n",
    "- Inverse Document Frequency : how unique a word is\n",
    "    - calculation: </br>\n",
    "        <code> IDF(t) = log_e(Total number of documents / Number of documents with term t in it) </code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_sentence = sent_tokenize(dirty_claim)\n",
    "total_docs = len(dirty_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1/41: 1.\n",
      "Sentence 2/41: A method comprising: using a first reader to take a first reading of an inherent disorder feature of a tag; using at least a second reader to take at least a second reading of the inherent disorder feature of the tag; matching the first reading with at least the second reading; determining one or more acceptance criteria, wherein at least one of the acceptance criteria is based on whether the first reading and the second reading match within a predetermined threshold; accepting the tag if the acceptance criteria are met; and recording a fingerprint for the tag if the tag was accepted.\n",
      "Sentence 3/41: 2.\n",
      "Sentence 4/41: The method of claim 1, wherein determining one or more acceptance criteria further comprises: determining an acceptance criterion based on an individual reading.\n",
      "Sentence 5/41: 3.\n",
      "Sentence 6/41: The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a strength of a signal in at least one of the first reading and the second reading.\n",
      "Sentence 7/41: 4.\n",
      "Sentence 8/41: The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a complexity of a signal in at least one of the first reading and the second reading.\n",
      "Sentence 9/41: 5.\n",
      "Sentence 10/41: The method of claim 1, further comprising: rejecting the tag if it is not accepted.\n",
      "Sentence 11/41: 6.\n",
      "Sentence 12/41: The method of claim 5, wherein rejecting the tag comprises removing the tag without stopping the flow of production.\n",
      "Sentence 13/41: 7.\n",
      "Sentence 14/41: The method of claim 6, wherein removing the tag comprises one or more of marking the tag as rejected, cutting out the tag, punching out the tag, and removing a tag using a suction method.\n",
      "Sentence 15/41: 8.\n",
      "Sentence 16/41: The method of claim 5, wherein rejecting the tag further comprises noting the rejected tag in a database.\n",
      "Sentence 17/41: 9.\n",
      "Sentence 18/41: The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag if the acceptance criteria are not met; matching the third reading with the first reading and the second reading; determining one or more further acceptance criteria, wherein at least one of the further acceptance criteria is based on whether the first reading and the third reading match within the predetermined threshold or whether the second reading and the third reading match within the predetermined threshold; and accepting the tag if the further acceptance criteria are met; and if the tag is accepted, recording a fingerprint for the tag based on the first reading if the first reading and the third reading match within the predetermined threshold or based on the second reading if the second reading and the third reading match within the predetermined threshold.\n",
      "Sentence 19/41: 10.\n",
      "Sentence 20/41: The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag; matching the third reading with the first reading and the second reading; determining an acceptance criterion based on whether the first reading and the third reading match within the predetermined threshold; and determining an acceptance criterion based on whether the second reading and the third reading match within the predetermined threshold.\n",
      "Sentence 21/41: 11.\n",
      "Sentence 22/41: The method of claim 10, further comprising: checking the performance of the first reader, the second reader, and the third reader.\n",
      "Sentence 23/41: 12.\n",
      "Sentence 24/41: The method of claim 11, wherein checking the performance of the first reader, the second reader, and the third reader comprises determining if one of the first reader, the second reader, or the third reader provides readings that are different from the other two readers.\n",
      "Sentence 25/41: 13.\n",
      "Sentence 26/41: The method of claim 1, further comprising: varying the conditions for each of the first, second, and third readers, so that readings from each of the first, the second, and the third readers cover a range of conditions within predetermined thresholds.\n",
      "Sentence 27/41: 14.\n",
      "Sentence 28/41: The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers.\n",
      "Sentence 29/41: 15.\n",
      "Sentence 30/41: The method of claim 13, wherein varying the conditions comprises varying the conditions to cover the expected range of conditions for readers that will be used in the field.\n",
      "Sentence 31/41: 16.\n",
      "Sentence 32/41: The method of claim 13, wherein varying the conditions comprises offsetting each of the first, second, and third readers from each other.\n",
      "Sentence 33/41: 17.\n",
      "Sentence 34/41: The method of claim 16, wherein offsetting each of the first, second, and third readers from each other comprises offsetting each of the first, second, and third readers from each other by a constant offset.\n",
      "Sentence 35/41: 18.\n",
      "Sentence 36/41: The method of claim 17, further comprising using false acceptance rate and false rejection rate tolerances to determine the constant offset.\n",
      "Sentence 37/41: 19.\n",
      "Sentence 38/41: The method of claim 17, further comprising using the constant offset to determine a minimum number of readers to be used.\n",
      "Sentence 39/41: 20-25.\n",
      "Sentence 40/41: (canceled) 26.\n",
      "Sentence 41/41: The method of claim 1, wherein the method is configured to read and verify the tag based on the inherent disorder function during a manufacturing process.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(dirty_sentence):\n",
    "    print(f\"Sentence {i+1}/{total_docs}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because the claim sentences are divided into two parts: one is number and one is claims, <code> combined_sentence </code> array is created to combine those divided part into one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1/22: 1. A method comprising: using a first reader to take a first reading of an inherent disorder feature of a tag; using at least a second reader to take at least a second reading of the inherent disorder feature of the tag; matching the first reading with at least the second reading; determining one or more acceptance criteria, wherein at least one of the acceptance criteria is based on whether the first reading and the second reading match within a predetermined threshold; accepting the tag if the acceptance criteria are met; and recording a fingerprint for the tag if the tag was accepted.\n",
      "Sentence 2/22: 2. The method of claim 1, wherein determining one or more acceptance criteria further comprises: determining an acceptance criterion based on an individual reading.\n",
      "Sentence 3/22: 3. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a strength of a signal in at least one of the first reading and the second reading.\n",
      "Sentence 4/22: 4. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a complexity of a signal in at least one of the first reading and the second reading.\n",
      "Sentence 5/22: 5. The method of claim 1, further comprising: rejecting the tag if it is not accepted.\n",
      "Sentence 6/22: 6. The method of claim 5, wherein rejecting the tag comprises removing the tag without stopping the flow of production.\n",
      "Sentence 7/22: 7. The method of claim 6, wherein removing the tag comprises one or more of marking the tag as rejected, cutting out the tag, punching out the tag, and removing a tag using a suction method.\n",
      "Sentence 8/22: 8. The method of claim 5, wherein rejecting the tag further comprises noting the rejected tag in a database.\n",
      "Sentence 9/22: 9. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag if the acceptance criteria are not met; matching the third reading with the first reading and the second reading; determining one or more further acceptance criteria, wherein at least one of the further acceptance criteria is based on whether the first reading and the third reading match within the predetermined threshold or whether the second reading and the third reading match within the predetermined threshold; and accepting the tag if the further acceptance criteria are met; and if the tag is accepted, recording a fingerprint for the tag based on the first reading if the first reading and the third reading match within the predetermined threshold or based on the second reading if the second reading and the third reading match within the predetermined threshold.\n",
      "Sentence 10/22: 10. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag; matching the third reading with the first reading and the second reading; determining an acceptance criterion based on whether the first reading and the third reading match within the predetermined threshold; and determining an acceptance criterion based on whether the second reading and the third reading match within the predetermined threshold.\n",
      "Sentence 11/22: 11. The method of claim 10, further comprising: checking the performance of the first reader, the second reader, and the third reader.\n",
      "Sentence 12/22: 12. The method of claim 11, wherein checking the performance of the first reader, the second reader, and the third reader comprises determining if one of the first reader, the second reader, or the third reader provides readings that are different from the other two readers.\n",
      "Sentence 13/22: 13. The method of claim 1, further comprising: varying the conditions for each of the first, second, and third readers, so that readings from each of the first, the second, and the third readers cover a range of conditions within predetermined thresholds.\n",
      "Sentence 14/22: 14. The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers.\n",
      "Sentence 15/22: 15. The method of claim 13, wherein varying the conditions comprises varying the conditions to cover the expected range of conditions for readers that will be used in the field.\n",
      "Sentence 16/22: 16. The method of claim 13, wherein varying the conditions comprises offsetting each of the first, second, and third readers from each other.\n",
      "Sentence 17/22: 17. The method of claim 16, wherein offsetting each of the first, second, and third readers from each other comprises offsetting each of the first, second, and third readers from each other by a constant offset.\n",
      "Sentence 18/22: 18. The method of claim 17, further comprising using false acceptance rate and false rejection rate tolerances to determine the constant offset.\n",
      "Sentence 19/22: 19. The method of claim 17, further comprising using the constant offset to determine a minimum number of readers to be used.\n",
      "Sentence 20/22: 20-25.\n",
      "Sentence 21/22: (canceled) 26.\n",
      "Sentence 22/22: The method of claim 1, wherein the method is configured to read and verify the tag based on the inherent disorder function during a manufacturing process.\n"
     ]
    }
   ],
   "source": [
    "combined_sentences = []\n",
    "i = 0\n",
    "\n",
    "while i < len(dirty_sentence):\n",
    "    current_sentence = dirty_sentence[i]\n",
    "    next_index = i + 1\n",
    "\n",
    "    if current_sentence.replace('.', '').isdigit():\n",
    "        if next_index < len(dirty_sentence) and not dirty_sentence[next_index].replace('.', '').isdigit():\n",
    "            current_sentence += \" \" + dirty_sentence[next_index]\n",
    "            i = next_index \n",
    "    combined_sentences.append(current_sentence)\n",
    "    i += 1\n",
    "\n",
    "for index, sentence in enumerate(combined_sentences):\n",
    "    print(f\"Sentence {index+1}/{len(combined_sentences)}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Frequency Matrix Calcuation </strong> </br>\n",
    "- An empty dictionary called <code> frequency_matrix</code> is created to store the frequency of the words\n",
    "- <strong> Stopwords & PorterStemmer  </strong> is used to remove the stopwords and stemming the words.\n",
    "- each sentence is being tokenized into word level and count the tokens and put in the freq_table to store the frequencies of the word.\n",
    "- Each words are converted into lowercase and then stemmed. stopwords are being ignored in this step. For each word, this block checks if it's already in the freq_table.\n",
    "- If it is, the frequency count is incremented.\n",
    "- If not, the word is added to the table with a frequency count of 1.\n",
    "- The frequency table for each sentence is added to the frequency_matrix with a key. The key is the length of the sentence for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. A method comprising: using a first reader to take a first reading of an inherent disorder feature of a tag; using at least a second reader to take at least a second reading of the inherent disorder feature of the tag; matching the first reading with at least the second reading; determining one or more acceptance criteria, wherein at least one of the acceptance criteria is based on whether the first reading and the second reading match within a predetermined threshold; accepting the tag if the acceptance criteria are met; and recording a fingerprint for the tag if the tag was accepted.': {'1': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'use': 2,\n",
       "  'first': 4,\n",
       "  'reader': 2,\n",
       "  'take': 2,\n",
       "  'read': 6,\n",
       "  'inher': 2,\n",
       "  'disord': 2,\n",
       "  'featur': 2,\n",
       "  'tag': 5,\n",
       "  ';': 5,\n",
       "  'least': 4,\n",
       "  'second': 4,\n",
       "  'match': 2,\n",
       "  'determin': 1,\n",
       "  'one': 2,\n",
       "  'accept': 5,\n",
       "  'criteria': 3,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'base': 1,\n",
       "  'whether': 1,\n",
       "  'within': 1,\n",
       "  'predetermin': 1,\n",
       "  'threshold': 1,\n",
       "  'met': 1,\n",
       "  'record': 1,\n",
       "  'fingerprint': 1,\n",
       "  'wa': 1},\n",
       " '2. The method of claim 1, wherein determining one or more acceptance criteria further comprises: determining an acceptance criterion based on an individual reading.': {'2': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '1': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'determin': 2,\n",
       "  'one': 1,\n",
       "  'accept': 2,\n",
       "  'criteria': 1,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'criterion': 1,\n",
       "  'base': 1,\n",
       "  'individu': 1,\n",
       "  'read': 1},\n",
       " '3. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a strength of a signal in at least one of the first reading and the second reading.': {'3': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '2': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'determin': 2,\n",
       "  'accept': 2,\n",
       "  'criterion': 2,\n",
       "  'base': 2,\n",
       "  'individu': 1,\n",
       "  'read': 3,\n",
       "  'compris': 1,\n",
       "  'strength': 1,\n",
       "  'signal': 1,\n",
       "  'least': 1,\n",
       "  'one': 1,\n",
       "  'first': 1,\n",
       "  'second': 1},\n",
       " '4. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a complexity of a signal in at least one of the first reading and the second reading.': {'4': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '2': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'determin': 2,\n",
       "  'accept': 2,\n",
       "  'criterion': 2,\n",
       "  'base': 2,\n",
       "  'individu': 1,\n",
       "  'read': 3,\n",
       "  'compris': 1,\n",
       "  'complex': 1,\n",
       "  'signal': 1,\n",
       "  'least': 1,\n",
       "  'one': 1,\n",
       "  'first': 1,\n",
       "  'second': 1},\n",
       " '5. The method of claim 1, further comprising: rejecting the tag if it is not accepted.': {'5': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '1': 1,\n",
       "  ',': 1,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'reject': 1,\n",
       "  'tag': 1,\n",
       "  'accept': 1},\n",
       " '6. The method of claim 5, wherein rejecting the tag comprises removing the tag without stopping the flow of production.': {'6': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '5': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'reject': 1,\n",
       "  'tag': 2,\n",
       "  'compris': 1,\n",
       "  'remov': 1,\n",
       "  'without': 1,\n",
       "  'stop': 1,\n",
       "  'flow': 1,\n",
       "  'product': 1},\n",
       " '7. The method of claim 6, wherein removing the tag comprises one or more of marking the tag as rejected, cutting out the tag, punching out the tag, and removing a tag using a suction method.': {'7': 1,\n",
       "  '.': 2,\n",
       "  'method': 2,\n",
       "  'claim': 1,\n",
       "  '6': 1,\n",
       "  ',': 4,\n",
       "  'wherein': 1,\n",
       "  'remov': 2,\n",
       "  'tag': 5,\n",
       "  'compris': 1,\n",
       "  'one': 1,\n",
       "  'mark': 1,\n",
       "  'reject': 1,\n",
       "  'cut': 1,\n",
       "  'punch': 1,\n",
       "  'use': 1,\n",
       "  'suction': 1},\n",
       " '8. The method of claim 5, wherein rejecting the tag further comprises noting the rejected tag in a database.': {'8': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '5': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'reject': 2,\n",
       "  'tag': 2,\n",
       "  'compris': 1,\n",
       "  'note': 1,\n",
       "  'databas': 1},\n",
       " '9. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag if the acceptance criteria are not met; matching the third reading with the first reading and the second reading; determining one or more further acceptance criteria, wherein at least one of the further acceptance criteria is based on whether the first reading and the third reading match within the predetermined threshold or whether the second reading and the third reading match within the predetermined threshold; and accepting the tag if the further acceptance criteria are met; and if the tag is accepted, recording a fingerprint for the tag based on the first reading if the first reading and the third reading match within the predetermined threshold or based on the second reading if the second reading and the third reading match within the predetermined threshold.': {'9': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '1': 1,\n",
       "  ',': 3,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'use': 1,\n",
       "  'least': 3,\n",
       "  'third': 7,\n",
       "  'reader': 1,\n",
       "  'take': 1,\n",
       "  'read': 14,\n",
       "  'inher': 1,\n",
       "  'disord': 1,\n",
       "  'featur': 1,\n",
       "  'tag': 4,\n",
       "  'accept': 6,\n",
       "  'criteria': 4,\n",
       "  'met': 2,\n",
       "  ';': 4,\n",
       "  'match': 5,\n",
       "  'first': 4,\n",
       "  'second': 4,\n",
       "  'determin': 1,\n",
       "  'one': 2,\n",
       "  'wherein': 1,\n",
       "  'base': 3,\n",
       "  'whether': 2,\n",
       "  'within': 4,\n",
       "  'predetermin': 4,\n",
       "  'threshold': 4,\n",
       "  'record': 1,\n",
       "  'fingerprint': 1},\n",
       " '10. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag; matching the third reading with the first reading and the second reading; determining an acceptance criterion based on whether the first reading and the third reading match within the predetermined threshold; and determining an acceptance criterion based on whether the second reading and the third reading match within the predetermined threshold.': {'10': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '1': 1,\n",
       "  ',': 1,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'use': 1,\n",
       "  'least': 2,\n",
       "  'third': 5,\n",
       "  'reader': 1,\n",
       "  'take': 1,\n",
       "  'read': 8,\n",
       "  'inher': 1,\n",
       "  'disord': 1,\n",
       "  'featur': 1,\n",
       "  'tag': 1,\n",
       "  ';': 3,\n",
       "  'match': 3,\n",
       "  'first': 2,\n",
       "  'second': 2,\n",
       "  'determin': 2,\n",
       "  'accept': 2,\n",
       "  'criterion': 2,\n",
       "  'base': 2,\n",
       "  'whether': 2,\n",
       "  'within': 2,\n",
       "  'predetermin': 2,\n",
       "  'threshold': 2},\n",
       " '11. The method of claim 10, further comprising: checking the performance of the first reader, the second reader, and the third reader.': {'11': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '10': 1,\n",
       "  ',': 3,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'check': 1,\n",
       "  'perform': 1,\n",
       "  'first': 1,\n",
       "  'reader': 3,\n",
       "  'second': 1,\n",
       "  'third': 1},\n",
       " '12. The method of claim 11, wherein checking the performance of the first reader, the second reader, and the third reader comprises determining if one of the first reader, the second reader, or the third reader provides readings that are different from the other two readers.': {'12': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '11': 1,\n",
       "  ',': 5,\n",
       "  'wherein': 1,\n",
       "  'check': 1,\n",
       "  'perform': 1,\n",
       "  'first': 2,\n",
       "  'reader': 7,\n",
       "  'second': 2,\n",
       "  'third': 2,\n",
       "  'compris': 1,\n",
       "  'determin': 1,\n",
       "  'one': 1,\n",
       "  'provid': 1,\n",
       "  'read': 1,\n",
       "  'differ': 1,\n",
       "  'two': 1},\n",
       " '13. The method of claim 1, further comprising: varying the conditions for each of the first, second, and third readers, so that readings from each of the first, the second, and the third readers cover a range of conditions within predetermined thresholds.': {'13': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '1': 1,\n",
       "  ',': 6,\n",
       "  'compris': 1,\n",
       "  ':': 1,\n",
       "  'vari': 1,\n",
       "  'condit': 2,\n",
       "  'first': 2,\n",
       "  'second': 2,\n",
       "  'third': 2,\n",
       "  'reader': 2,\n",
       "  'read': 1,\n",
       "  'cover': 1,\n",
       "  'rang': 1,\n",
       "  'within': 1,\n",
       "  'predetermin': 1,\n",
       "  'threshold': 1},\n",
       " '14. The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers.': {'14': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '13': 1,\n",
       "  ',': 4,\n",
       "  'wherein': 1,\n",
       "  'vari': 2,\n",
       "  'condit': 2,\n",
       "  'compris': 1,\n",
       "  'least': 5,\n",
       "  'one': 5,\n",
       "  'age': 1,\n",
       "  'reader': 4,\n",
       "  'temperatur': 1,\n",
       "  'construct': 1,\n",
       "  'compon': 1},\n",
       " '15. The method of claim 13, wherein varying the conditions comprises varying the conditions to cover the expected range of conditions for readers that will be used in the field.': {'15': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '13': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'vari': 2,\n",
       "  'condit': 3,\n",
       "  'compris': 1,\n",
       "  'cover': 1,\n",
       "  'expect': 1,\n",
       "  'rang': 1,\n",
       "  'reader': 1,\n",
       "  'use': 1,\n",
       "  'field': 1},\n",
       " '16. The method of claim 13, wherein varying the conditions comprises offsetting each of the first, second, and third readers from each other.': {'16': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '13': 1,\n",
       "  ',': 3,\n",
       "  'wherein': 1,\n",
       "  'vari': 1,\n",
       "  'condit': 1,\n",
       "  'compris': 1,\n",
       "  'offset': 1,\n",
       "  'first': 1,\n",
       "  'second': 1,\n",
       "  'third': 1,\n",
       "  'reader': 1},\n",
       " '17. The method of claim 16, wherein offsetting each of the first, second, and third readers from each other comprises offsetting each of the first, second, and third readers from each other by a constant offset.': {'17': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '16': 1,\n",
       "  ',': 5,\n",
       "  'wherein': 1,\n",
       "  'offset': 3,\n",
       "  'first': 2,\n",
       "  'second': 2,\n",
       "  'third': 2,\n",
       "  'reader': 2,\n",
       "  'compris': 1,\n",
       "  'constant': 1},\n",
       " '18. The method of claim 17, further comprising using false acceptance rate and false rejection rate tolerances to determine the constant offset.': {'18': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '17': 1,\n",
       "  ',': 1,\n",
       "  'compris': 1,\n",
       "  'use': 1,\n",
       "  'fals': 2,\n",
       "  'accept': 1,\n",
       "  'rate': 2,\n",
       "  'reject': 1,\n",
       "  'toler': 1,\n",
       "  'determin': 1,\n",
       "  'constant': 1,\n",
       "  'offset': 1},\n",
       " '19. The method of claim 17, further comprising using the constant offset to determine a minimum number of readers to be used.': {'19': 1,\n",
       "  '.': 2,\n",
       "  'method': 1,\n",
       "  'claim': 1,\n",
       "  '17': 1,\n",
       "  ',': 1,\n",
       "  'compris': 1,\n",
       "  'use': 2,\n",
       "  'constant': 1,\n",
       "  'offset': 1,\n",
       "  'determin': 1,\n",
       "  'minimum': 1,\n",
       "  'number': 1,\n",
       "  'reader': 1},\n",
       " '20-25.': {'20-25': 1, '.': 1},\n",
       " '(canceled) 26.': {'(': 1, 'cancel': 1, ')': 1, '26': 1, '.': 1},\n",
       " 'The method of claim 1, wherein the method is configured to read and verify the tag based on the inherent disorder function during a manufacturing process.': {'method': 2,\n",
       "  'claim': 1,\n",
       "  '1': 1,\n",
       "  ',': 1,\n",
       "  'wherein': 1,\n",
       "  'configur': 1,\n",
       "  'read': 1,\n",
       "  'verifi': 1,\n",
       "  'tag': 1,\n",
       "  'base': 1,\n",
       "  'inher': 1,\n",
       "  'disord': 1,\n",
       "  'function': 1,\n",
       "  'dure': 1,\n",
       "  'manufactur': 1,\n",
       "  'process': 1,\n",
       "  '.': 1}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:len(sent)]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "freq_matrix = _create_frequency_matrix(combined_sentences)\n",
    "freq_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> TF Matrix Calcuation </strong>\n",
    "- <code> tf_matrix </code> dictionary is created to store the term frequency for each word in each sentence.\n",
    "- loop over the freq_matrix. sent will be the sentence, and f_table is the corresponding frequency table for that sentence.\n",
    "- For each sentence, a new empty dictionary <code> tf_table </code> is created. This will store the term frequencies for words in this particular sentence.\n",
    "- The function then iterates over each word and its count in the frequency table. It calculates the term frequency by dividing the count of each word by the total word count in the sentence, and stores this value in <code> tf_table. </code>\n",
    "- The term frequency table <code> tf_table </code> for each sentence is then stored in the  <code> tf_matrix </code> with the sentence as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = _create_tf_matrix(freq_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we calculate, “how many sentences contain a word”, Let’s call it Documents per words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "count_doc_per_words = _create_documents_per_words(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 7,\n",
       " '.': 22,\n",
       " 'method': 20,\n",
       " 'compris': 19,\n",
       " ':': 7,\n",
       " 'use': 7,\n",
       " 'first': 10,\n",
       " 'reader': 11,\n",
       " 'take': 3,\n",
       " 'read': 9,\n",
       " 'inher': 4,\n",
       " 'disord': 4,\n",
       " 'featur': 3,\n",
       " 'tag': 8,\n",
       " ';': 3,\n",
       " 'least': 6,\n",
       " 'second': 10,\n",
       " 'match': 3,\n",
       " 'determin': 9,\n",
       " 'one': 8,\n",
       " 'accept': 8,\n",
       " 'criteria': 3,\n",
       " ',': 20,\n",
       " 'wherein': 14,\n",
       " 'base': 7,\n",
       " 'whether': 3,\n",
       " 'within': 4,\n",
       " 'predetermin': 4,\n",
       " 'threshold': 4,\n",
       " 'met': 2,\n",
       " 'record': 2,\n",
       " 'fingerprint': 2,\n",
       " 'wa': 1,\n",
       " '2': 3,\n",
       " 'claim': 19,\n",
       " 'criterion': 4,\n",
       " 'individu': 3,\n",
       " '3': 1,\n",
       " 'strength': 1,\n",
       " 'signal': 2,\n",
       " '4': 1,\n",
       " 'complex': 1,\n",
       " '5': 3,\n",
       " 'reject': 5,\n",
       " '6': 2,\n",
       " 'remov': 2,\n",
       " 'without': 1,\n",
       " 'stop': 1,\n",
       " 'flow': 1,\n",
       " 'product': 1,\n",
       " '7': 1,\n",
       " 'mark': 1,\n",
       " 'cut': 1,\n",
       " 'punch': 1,\n",
       " 'suction': 1,\n",
       " '8': 1,\n",
       " 'note': 1,\n",
       " 'databas': 1,\n",
       " '9': 1,\n",
       " 'third': 7,\n",
       " '10': 2,\n",
       " '11': 2,\n",
       " 'check': 2,\n",
       " 'perform': 2,\n",
       " '12': 1,\n",
       " 'provid': 1,\n",
       " 'differ': 1,\n",
       " 'two': 1,\n",
       " '13': 4,\n",
       " 'vari': 4,\n",
       " 'condit': 4,\n",
       " 'cover': 2,\n",
       " 'rang': 2,\n",
       " '14': 1,\n",
       " 'age': 1,\n",
       " 'temperatur': 1,\n",
       " 'construct': 1,\n",
       " 'compon': 1,\n",
       " '15': 1,\n",
       " 'expect': 1,\n",
       " 'field': 1,\n",
       " '16': 2,\n",
       " 'offset': 4,\n",
       " '17': 3,\n",
       " 'constant': 3,\n",
       " '18': 1,\n",
       " 'fals': 1,\n",
       " 'rate': 1,\n",
       " 'toler': 1,\n",
       " '19': 1,\n",
       " 'minimum': 1,\n",
       " 'number': 1,\n",
       " '20-25': 1,\n",
       " '(': 1,\n",
       " 'cancel': 1,\n",
       " ')': 1,\n",
       " '26': 1,\n",
       " 'configur': 1,\n",
       " 'verifi': 1,\n",
       " 'function': 1,\n",
       " 'dure': 1,\n",
       " 'manufactur': 1,\n",
       " 'process': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_doc_per_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result means: 1 appear in 9 sentence and antioxid appears in 12 sentences etc etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after that, calcuate idf according to the formula <code> IDF(t) = log_e(Total number of documents / Number of documents with term t in it) </code> which is the number from the above result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words,total_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. A method comprising: using a first reader to take a first reading of an inherent disorder feature of a tag; using at least a second reader to take at least a second reading of the inherent disorder feature of the tag; matching the first reading with at least the second reading; determining one or more acceptance criteria, wherein at least one of the acceptance criteria is based on whether the first reading and the second reading match within a predetermined threshold; accepting the tag if the acceptance criteria are met; and recording a fingerprint for the tag if the tag was accepted.': {'1': 0.7676858167054786,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'use': 0.7676858167054786,\n",
       "  'first': 0.6127838567197355,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'take': 1.135662602000073,\n",
       "  'read': 0.6585413472804106,\n",
       "  'inher': 1.0107238653917732,\n",
       "  'disord': 1.0107238653917732,\n",
       "  'featur': 1.135662602000073,\n",
       "  'tag': 0.7096938697277919,\n",
       "  ';': 1.135662602000073,\n",
       "  'least': 0.8346326063360918,\n",
       "  'second': 0.6127838567197355,\n",
       "  'match': 1.135662602000073,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'one': 0.7096938697277919,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'criteria': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'base': 0.7676858167054786,\n",
       "  'whether': 1.135662602000073,\n",
       "  'within': 1.0107238653917732,\n",
       "  'predetermin': 1.0107238653917732,\n",
       "  'threshold': 1.0107238653917732,\n",
       "  'met': 1.3117538610557542,\n",
       "  'record': 1.3117538610557542,\n",
       "  'fingerprint': 1.3117538610557542,\n",
       "  'wa': 1.6127838567197355},\n",
       " '2. The method of claim 1, wherein determining one or more acceptance criteria further comprises: determining an acceptance criterion based on an individual reading.': {'2': 1.135662602000073,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '1': 0.7676858167054786,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'one': 0.7096938697277919,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'criteria': 1.135662602000073,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'criterion': 1.0107238653917732,\n",
       "  'base': 0.7676858167054786,\n",
       "  'individu': 1.135662602000073,\n",
       "  'read': 0.6585413472804106},\n",
       " '3. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a strength of a signal in at least one of the first reading and the second reading.': {'3': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '2': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'criterion': 1.0107238653917732,\n",
       "  'base': 0.7676858167054786,\n",
       "  'individu': 1.135662602000073,\n",
       "  'read': 0.6585413472804106,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'strength': 1.6127838567197355,\n",
       "  'signal': 1.3117538610557542,\n",
       "  'least': 0.8346326063360918,\n",
       "  'one': 0.7096938697277919,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355},\n",
       " '4. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a complexity of a signal in at least one of the first reading and the second reading.': {'4': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '2': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'criterion': 1.0107238653917732,\n",
       "  'base': 0.7676858167054786,\n",
       "  'individu': 1.135662602000073,\n",
       "  'read': 0.6585413472804106,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'complex': 1.6127838567197355,\n",
       "  'signal': 1.3117538610557542,\n",
       "  'least': 0.8346326063360918,\n",
       "  'one': 0.7096938697277919,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355},\n",
       " '5. The method of claim 1, further comprising: rejecting the tag if it is not accepted.': {'5': 1.135662602000073,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '1': 0.7676858167054786,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'reject': 0.9138138523837167,\n",
       "  'tag': 0.7096938697277919,\n",
       "  'accept': 0.7096938697277919},\n",
       " '6. The method of claim 5, wherein rejecting the tag comprises removing the tag without stopping the flow of production.': {'6': 1.3117538610557542,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '5': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'reject': 0.9138138523837167,\n",
       "  'tag': 0.7096938697277919,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'remov': 1.3117538610557542,\n",
       "  'without': 1.6127838567197355,\n",
       "  'stop': 1.6127838567197355,\n",
       "  'flow': 1.6127838567197355,\n",
       "  'product': 1.6127838567197355},\n",
       " '7. The method of claim 6, wherein removing the tag comprises one or more of marking the tag as rejected, cutting out the tag, punching out the tag, and removing a tag using a suction method.': {'7': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '6': 1.3117538610557542,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'remov': 1.3117538610557542,\n",
       "  'tag': 0.7096938697277919,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'one': 0.7096938697277919,\n",
       "  'mark': 1.6127838567197355,\n",
       "  'reject': 0.9138138523837167,\n",
       "  'cut': 1.6127838567197355,\n",
       "  'punch': 1.6127838567197355,\n",
       "  'use': 0.7676858167054786,\n",
       "  'suction': 1.6127838567197355},\n",
       " '8. The method of claim 5, wherein rejecting the tag further comprises noting the rejected tag in a database.': {'8': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '5': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'reject': 0.9138138523837167,\n",
       "  'tag': 0.7096938697277919,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'note': 1.6127838567197355,\n",
       "  'databas': 1.6127838567197355},\n",
       " '9. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag if the acceptance criteria are not met; matching the third reading with the first reading and the second reading; determining one or more further acceptance criteria, wherein at least one of the further acceptance criteria is based on whether the first reading and the third reading match within the predetermined threshold or whether the second reading and the third reading match within the predetermined threshold; and accepting the tag if the further acceptance criteria are met; and if the tag is accepted, recording a fingerprint for the tag based on the first reading if the first reading and the third reading match within the predetermined threshold or based on the second reading if the second reading and the third reading match within the predetermined threshold.': {'9': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '1': 0.7676858167054786,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'use': 0.7676858167054786,\n",
       "  'least': 0.8346326063360918,\n",
       "  'third': 0.7676858167054786,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'take': 1.135662602000073,\n",
       "  'read': 0.6585413472804106,\n",
       "  'inher': 1.0107238653917732,\n",
       "  'disord': 1.0107238653917732,\n",
       "  'featur': 1.135662602000073,\n",
       "  'tag': 0.7096938697277919,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'criteria': 1.135662602000073,\n",
       "  'met': 1.3117538610557542,\n",
       "  ';': 1.135662602000073,\n",
       "  'match': 1.135662602000073,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'one': 0.7096938697277919,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'base': 0.7676858167054786,\n",
       "  'whether': 1.135662602000073,\n",
       "  'within': 1.0107238653917732,\n",
       "  'predetermin': 1.0107238653917732,\n",
       "  'threshold': 1.0107238653917732,\n",
       "  'record': 1.3117538610557542,\n",
       "  'fingerprint': 1.3117538610557542},\n",
       " '10. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag; matching the third reading with the first reading and the second reading; determining an acceptance criterion based on whether the first reading and the third reading match within the predetermined threshold; and determining an acceptance criterion based on whether the second reading and the third reading match within the predetermined threshold.': {'10': 1.3117538610557542,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '1': 0.7676858167054786,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'use': 0.7676858167054786,\n",
       "  'least': 0.8346326063360918,\n",
       "  'third': 0.7676858167054786,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'take': 1.135662602000073,\n",
       "  'read': 0.6585413472804106,\n",
       "  'inher': 1.0107238653917732,\n",
       "  'disord': 1.0107238653917732,\n",
       "  'featur': 1.135662602000073,\n",
       "  'tag': 0.7096938697277919,\n",
       "  ';': 1.135662602000073,\n",
       "  'match': 1.135662602000073,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'criterion': 1.0107238653917732,\n",
       "  'base': 0.7676858167054786,\n",
       "  'whether': 1.135662602000073,\n",
       "  'within': 1.0107238653917732,\n",
       "  'predetermin': 1.0107238653917732,\n",
       "  'threshold': 1.0107238653917732},\n",
       " '11. The method of claim 10, further comprising: checking the performance of the first reader, the second reader, and the third reader.': {'11': 1.3117538610557542,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '10': 1.3117538610557542,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'check': 1.3117538610557542,\n",
       "  'perform': 1.3117538610557542,\n",
       "  'first': 0.6127838567197355,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'second': 0.6127838567197355,\n",
       "  'third': 0.7676858167054786},\n",
       " '12. The method of claim 11, wherein checking the performance of the first reader, the second reader, and the third reader comprises determining if one of the first reader, the second reader, or the third reader provides readings that are different from the other two readers.': {'12': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '11': 1.3117538610557542,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'check': 1.3117538610557542,\n",
       "  'perform': 1.3117538610557542,\n",
       "  'first': 0.6127838567197355,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'second': 0.6127838567197355,\n",
       "  'third': 0.7676858167054786,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'one': 0.7096938697277919,\n",
       "  'provid': 1.6127838567197355,\n",
       "  'read': 0.6585413472804106,\n",
       "  'differ': 1.6127838567197355,\n",
       "  'two': 1.6127838567197355},\n",
       " '13. The method of claim 1, further comprising: varying the conditions for each of the first, second, and third readers, so that readings from each of the first, the second, and the third readers cover a range of conditions within predetermined thresholds.': {'13': 1.0107238653917732,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '1': 0.7676858167054786,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  ':': 0.7676858167054786,\n",
       "  'vari': 1.0107238653917732,\n",
       "  'condit': 1.0107238653917732,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355,\n",
       "  'third': 0.7676858167054786,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'read': 0.6585413472804106,\n",
       "  'cover': 1.3117538610557542,\n",
       "  'rang': 1.3117538610557542,\n",
       "  'within': 1.0107238653917732,\n",
       "  'predetermin': 1.0107238653917732,\n",
       "  'threshold': 1.0107238653917732},\n",
       " '14. The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers.': {'14': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '13': 1.0107238653917732,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'vari': 1.0107238653917732,\n",
       "  'condit': 1.0107238653917732,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'least': 0.8346326063360918,\n",
       "  'one': 0.7096938697277919,\n",
       "  'age': 1.6127838567197355,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'temperatur': 1.6127838567197355,\n",
       "  'construct': 1.6127838567197355,\n",
       "  'compon': 1.6127838567197355},\n",
       " '15. The method of claim 13, wherein varying the conditions comprises varying the conditions to cover the expected range of conditions for readers that will be used in the field.': {'15': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '13': 1.0107238653917732,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'vari': 1.0107238653917732,\n",
       "  'condit': 1.0107238653917732,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'cover': 1.3117538610557542,\n",
       "  'expect': 1.6127838567197355,\n",
       "  'rang': 1.3117538610557542,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'use': 0.7676858167054786,\n",
       "  'field': 1.6127838567197355},\n",
       " '16. The method of claim 13, wherein varying the conditions comprises offsetting each of the first, second, and third readers from each other.': {'16': 1.3117538610557542,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '13': 1.0107238653917732,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'vari': 1.0107238653917732,\n",
       "  'condit': 1.0107238653917732,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'offset': 1.0107238653917732,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355,\n",
       "  'third': 0.7676858167054786,\n",
       "  'reader': 0.5713911715615104},\n",
       " '17. The method of claim 16, wherein offsetting each of the first, second, and third readers from each other comprises offsetting each of the first, second, and third readers from each other by a constant offset.': {'17': 1.135662602000073,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '16': 1.3117538610557542,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'offset': 1.0107238653917732,\n",
       "  'first': 0.6127838567197355,\n",
       "  'second': 0.6127838567197355,\n",
       "  'third': 0.7676858167054786,\n",
       "  'reader': 0.5713911715615104,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'constant': 1.135662602000073},\n",
       " '18. The method of claim 17, further comprising using false acceptance rate and false rejection rate tolerances to determine the constant offset.': {'18': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '17': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'use': 0.7676858167054786,\n",
       "  'fals': 1.6127838567197355,\n",
       "  'accept': 0.7096938697277919,\n",
       "  'rate': 1.6127838567197355,\n",
       "  'reject': 0.9138138523837167,\n",
       "  'toler': 1.6127838567197355,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'constant': 1.135662602000073,\n",
       "  'offset': 1.0107238653917732},\n",
       " '19. The method of claim 17, further comprising using the constant offset to determine a minimum number of readers to be used.': {'19': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292,\n",
       "  'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '17': 1.135662602000073,\n",
       "  ',': 0.31175386105575426,\n",
       "  'compris': 0.33403025576690654,\n",
       "  'use': 0.7676858167054786,\n",
       "  'constant': 1.135662602000073,\n",
       "  'offset': 1.0107238653917732,\n",
       "  'determin': 0.6585413472804106,\n",
       "  'minimum': 1.6127838567197355,\n",
       "  'number': 1.6127838567197355,\n",
       "  'reader': 0.5713911715615104},\n",
       " '20-25.': {'20-25': 1.6127838567197355, '.': 0.2703611758975292},\n",
       " '(canceled) 26.': {'(': 1.6127838567197355,\n",
       "  'cancel': 1.6127838567197355,\n",
       "  ')': 1.6127838567197355,\n",
       "  '26': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292},\n",
       " 'The method of claim 1, wherein the method is configured to read and verify the tag based on the inherent disorder function during a manufacturing process.': {'method': 0.31175386105575426,\n",
       "  'claim': 0.33403025576690654,\n",
       "  '1': 0.7676858167054786,\n",
       "  ',': 0.31175386105575426,\n",
       "  'wherein': 0.46665582104149744,\n",
       "  'configur': 1.6127838567197355,\n",
       "  'read': 0.6585413472804106,\n",
       "  'verifi': 1.6127838567197355,\n",
       "  'tag': 0.7096938697277919,\n",
       "  'base': 0.7676858167054786,\n",
       "  'inher': 1.0107238653917732,\n",
       "  'disord': 1.0107238653917732,\n",
       "  'function': 1.6127838567197355,\n",
       "  'dure': 1.6127838567197355,\n",
       "  'manufactur': 1.6127838567197355,\n",
       "  'process': 1.6127838567197355,\n",
       "  '.': 0.2703611758975292}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcualte TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix\n",
    "\n",
    "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. A method comprising: using a first reader to take a first reading of an inherent disorder feature of a tag; using at least a second reader to take at least a second reading of the inherent disorder feature of the tag; matching the first reading with at least the second reading; determining one or more acceptance criteria, wherein at least one of the acceptance criteria is based on whether the first reading and the second reading match within a predetermined threshold; accepting the tag if the acceptance criteria are met; and recording a fingerprint for the tag if the tag was accepted.': {'1': 0.023263206566832687,\n",
       "  '.': 0.016385525811971467,\n",
       "  'method': 0.00944708669865922,\n",
       "  'compris': 0.010122128962633531,\n",
       "  ':': 0.023263206566832687,\n",
       "  'use': 0.04652641313366537,\n",
       "  'first': 0.0742768311175437,\n",
       "  'reader': 0.034629767973424874,\n",
       "  'take': 0.06882803648485292,\n",
       "  'read': 0.11973479041462011,\n",
       "  'inher': 0.06125599184192565,\n",
       "  'disord': 0.06125599184192565,\n",
       "  'featur': 0.06882803648485292,\n",
       "  'tag': 0.1075293742011806,\n",
       "  ';': 0.1720700912121323,\n",
       "  'least': 0.101167588646799,\n",
       "  'second': 0.0742768311175437,\n",
       "  'match': 0.06882803648485292,\n",
       "  'determin': 0.019955798402436685,\n",
       "  'one': 0.043011749680472236,\n",
       "  'accept': 0.1075293742011806,\n",
       "  'criteria': 0.10324205472727938,\n",
       "  ',': 0.00944708669865922,\n",
       "  'wherein': 0.014141085486105983,\n",
       "  'base': 0.023263206566832687,\n",
       "  'whether': 0.03441401824242646,\n",
       "  'within': 0.030627995920962825,\n",
       "  'predetermin': 0.030627995920962825,\n",
       "  'threshold': 0.030627995920962825,\n",
       "  'met': 0.039750117001689525,\n",
       "  'record': 0.039750117001689525,\n",
       "  'fingerprint': 0.039750117001689525,\n",
       "  'wa': 0.048872238082416225},\n",
       " '2. The method of claim 1, wherein determining one or more acceptance criteria further comprises: determining an acceptance criterion based on an individual reading.': {'2': 0.06680368247059253,\n",
       "  '.': 0.031807197164415206,\n",
       "  'method': 0.018338462415044367,\n",
       "  'claim': 0.019648838574523913,\n",
       "  '1': 0.04515798921796933,\n",
       "  ',': 0.018338462415044367,\n",
       "  'wherein': 0.02745034241420573,\n",
       "  'determin': 0.07747545262122478,\n",
       "  'one': 0.041746698219281876,\n",
       "  'accept': 0.08349339643856375,\n",
       "  'criteria': 0.06680368247059253,\n",
       "  'compris': 0.019648838574523913,\n",
       "  ':': 0.04515798921796933,\n",
       "  'criterion': 0.05945434502304548,\n",
       "  'base': 0.04515798921796933,\n",
       "  'individu': 0.06680368247059253,\n",
       "  'read': 0.03873772631061239},\n",
       " '3. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a strength of a signal in at least one of the first reading and the second reading.': {'3': 0.08063919283598678,\n",
       "  '.': 0.027036117589752925,\n",
       "  'method': 0.015587693052787713,\n",
       "  'claim': 0.016701512788345328,\n",
       "  '2': 0.05678313010000366,\n",
       "  ',': 0.015587693052787713,\n",
       "  'wherein': 0.023332791052074874,\n",
       "  'determin': 0.06585413472804107,\n",
       "  'accept': 0.0709693869727792,\n",
       "  'criterion': 0.10107238653917733,\n",
       "  'base': 0.07676858167054787,\n",
       "  'individu': 0.05678313010000366,\n",
       "  'read': 0.09878120209206158,\n",
       "  'compris': 0.016701512788345328,\n",
       "  'strength': 0.08063919283598678,\n",
       "  'signal': 0.06558769305278771,\n",
       "  'least': 0.041731630316804595,\n",
       "  'one': 0.0354846934863896,\n",
       "  'first': 0.030639192835986775,\n",
       "  'second': 0.030639192835986775},\n",
       " '4. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a complexity of a signal in at least one of the first reading and the second reading.': {'4': 0.08063919283598678,\n",
       "  '.': 0.027036117589752925,\n",
       "  'method': 0.015587693052787713,\n",
       "  'claim': 0.016701512788345328,\n",
       "  '2': 0.05678313010000366,\n",
       "  ',': 0.015587693052787713,\n",
       "  'wherein': 0.023332791052074874,\n",
       "  'determin': 0.06585413472804107,\n",
       "  'accept': 0.0709693869727792,\n",
       "  'criterion': 0.10107238653917733,\n",
       "  'base': 0.07676858167054787,\n",
       "  'individu': 0.05678313010000366,\n",
       "  'read': 0.09878120209206158,\n",
       "  'compris': 0.016701512788345328,\n",
       "  'complex': 0.08063919283598678,\n",
       "  'signal': 0.06558769305278771,\n",
       "  'least': 0.041731630316804595,\n",
       "  'one': 0.0354846934863896,\n",
       "  'first': 0.030639192835986775,\n",
       "  'second': 0.030639192835986775},\n",
       " '5. The method of claim 1, further comprising: rejecting the tag if it is not accepted.': {'5': 0.10324205472727938,\n",
       "  '.': 0.04915657743591441,\n",
       "  'method': 0.02834126009597766,\n",
       "  'claim': 0.030366386887900595,\n",
       "  '1': 0.06978961970049806,\n",
       "  ',': 0.02834126009597766,\n",
       "  'compris': 0.030366386887900595,\n",
       "  ':': 0.06978961970049806,\n",
       "  'reject': 0.08307398658033789,\n",
       "  'tag': 0.06451762452070836,\n",
       "  'accept': 0.06451762452070836},\n",
       " '6. The method of claim 5, wherein rejecting the tag comprises removing the tag without stopping the flow of production.': {'6': 0.08745025740371695,\n",
       "  '.': 0.03604815678633723,\n",
       "  'method': 0.020783590737050283,\n",
       "  'claim': 0.02226868371779377,\n",
       "  '5': 0.0757108401333382,\n",
       "  ',': 0.020783590737050283,\n",
       "  'wherein': 0.031110388069433163,\n",
       "  'reject': 0.06092092349224778,\n",
       "  'tag': 0.09462584929703892,\n",
       "  'compris': 0.02226868371779377,\n",
       "  'remov': 0.08745025740371695,\n",
       "  'without': 0.1075189237813157,\n",
       "  'stop': 0.1075189237813157,\n",
       "  'flow': 0.1075189237813157,\n",
       "  'product': 0.1075189237813157},\n",
       " '7. The method of claim 6, wherein removing the tag comprises one or more of marking the tag as rejected, cutting out the tag, punching out the tag, and removing a tag using a suction method.': {'7': 0.09486963863057267,\n",
       "  '.': 0.031807197164415206,\n",
       "  'method': 0.036676924830088733,\n",
       "  'claim': 0.019648838574523913,\n",
       "  '6': 0.07716199182680906,\n",
       "  ',': 0.07335384966017747,\n",
       "  'wherein': 0.02745034241420573,\n",
       "  'remov': 0.15432398365361813,\n",
       "  'tag': 0.2087334910964094,\n",
       "  'compris': 0.019648838574523913,\n",
       "  'one': 0.041746698219281876,\n",
       "  'mark': 0.09486963863057267,\n",
       "  'reject': 0.05375375602257157,\n",
       "  'cut': 0.09486963863057267,\n",
       "  'punch': 0.09486963863057267,\n",
       "  'use': 0.04515798921796933,\n",
       "  'suction': 0.09486963863057267},\n",
       " '8. The method of claim 5, wherein rejecting the tag further comprises noting the rejected tag in a database.': {'8': 0.1343986547266446,\n",
       "  '.': 0.04506019598292153,\n",
       "  'method': 0.025979488421312855,\n",
       "  'claim': 0.02783585464724221,\n",
       "  '5': 0.09463855016667275,\n",
       "  ',': 0.025979488421312855,\n",
       "  'wherein': 0.03888798508679145,\n",
       "  'reject': 0.15230230873061945,\n",
       "  'tag': 0.11828231162129865,\n",
       "  'compris': 0.02783585464724221,\n",
       "  'note': 0.1343986547266446,\n",
       "  'databas': 0.1343986547266446},\n",
       " '9. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag if the acceptance criteria are not met; matching the third reading with the first reading and the second reading; determining one or more further acceptance criteria, wherein at least one of the further acceptance criteria is based on whether the first reading and the third reading match within the predetermined threshold or whether the second reading and the third reading match within the predetermined threshold; and accepting the tag if the further acceptance criteria are met; and if the tag is accepted, recording a fingerprint for the tag based on the first reading if the first reading and the third reading match within the predetermined threshold or based on the second reading if the second reading and the third reading match within the predetermined threshold.': {'9': 0.04607953876342101,\n",
       "  '.': 0.015449210051287384,\n",
       "  'method': 0.00890725317302155,\n",
       "  'claim': 0.009543721593340186,\n",
       "  '1': 0.02193388047729939,\n",
       "  ',': 0.02672175951906465,\n",
       "  'compris': 0.009543721593340186,\n",
       "  ':': 0.02193388047729939,\n",
       "  'use': 0.02193388047729939,\n",
       "  'least': 0.07153993768595072,\n",
       "  'third': 0.15353716334109574,\n",
       "  'reader': 0.016325462044614582,\n",
       "  'take': 0.0324475029142878,\n",
       "  'read': 0.26341653891216427,\n",
       "  'inher': 0.028877824725479232,\n",
       "  'disord': 0.028877824725479232,\n",
       "  'featur': 0.0324475029142878,\n",
       "  'tag': 0.08110787082603337,\n",
       "  'accept': 0.12166180623905004,\n",
       "  'criteria': 0.1297900116571512,\n",
       "  'met': 0.07495736348890024,\n",
       "  ';': 0.1297900116571512,\n",
       "  'match': 0.162237514571439,\n",
       "  'first': 0.07003244076796976,\n",
       "  'second': 0.07003244076796976,\n",
       "  'determin': 0.01881546706515459,\n",
       "  'one': 0.04055393541301668,\n",
       "  'wherein': 0.013333023458328498,\n",
       "  'base': 0.06580164143189816,\n",
       "  'whether': 0.0648950058285756,\n",
       "  'within': 0.11551129890191693,\n",
       "  'predetermin': 0.11551129890191693,\n",
       "  'threshold': 0.11551129890191693,\n",
       "  'record': 0.03747868174445012,\n",
       "  'fingerprint': 0.03747868174445012},\n",
       " '10. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag; matching the third reading with the first reading and the second reading; determining an acceptance criterion based on whether the first reading and the third reading match within the predetermined threshold; and determining an acceptance criterion based on whether the second reading and the third reading match within the predetermined threshold.': {'10': 0.043725128701858476,\n",
       "  '.': 0.018024078393168615,\n",
       "  'method': 0.010391795368525142,\n",
       "  'claim': 0.011134341858896885,\n",
       "  '1': 0.025589527223515953,\n",
       "  ',': 0.010391795368525142,\n",
       "  'compris': 0.011134341858896885,\n",
       "  ':': 0.025589527223515953,\n",
       "  'use': 0.025589527223515953,\n",
       "  'least': 0.05564217375573945,\n",
       "  'third': 0.12794763611757975,\n",
       "  'reader': 0.019046372385383682,\n",
       "  'take': 0.0378554200666691,\n",
       "  'read': 0.17561102594144282,\n",
       "  'inher': 0.033690795513059105,\n",
       "  'disord': 0.033690795513059105,\n",
       "  'featur': 0.0378554200666691,\n",
       "  'tag': 0.02365646232425973,\n",
       "  ';': 0.11356626020000732,\n",
       "  'match': 0.11356626020000732,\n",
       "  'first': 0.04085225711464903,\n",
       "  'second': 0.04085225711464903,\n",
       "  'determin': 0.043902756485360704,\n",
       "  'accept': 0.04731292464851946,\n",
       "  'criterion': 0.06738159102611821,\n",
       "  'base': 0.051179054447031906,\n",
       "  'whether': 0.0757108401333382,\n",
       "  'within': 0.06738159102611821,\n",
       "  'predetermin': 0.06738159102611821,\n",
       "  'threshold': 0.06738159102611821},\n",
       " '11. The method of claim 10, further comprising: checking the performance of the first reader, the second reader, and the third reader.': {'11': 0.09369670436112529,\n",
       "  '.': 0.03862302512821846,\n",
       "  'method': 0.022268132932553874,\n",
       "  'claim': 0.023859303983350465,\n",
       "  '10': 0.09369670436112529,\n",
       "  ',': 0.06680439879766162,\n",
       "  'compris': 0.023859303983350465,\n",
       "  ':': 0.05483470119324847,\n",
       "  'check': 0.09369670436112529,\n",
       "  'perform': 0.09369670436112529,\n",
       "  'first': 0.0437702754799811,\n",
       "  'reader': 0.12244096533460937,\n",
       "  'second': 0.0437702754799811,\n",
       "  'third': 0.05483470119324847},\n",
       " '12. The method of claim 11, wherein checking the performance of the first reader, the second reader, and the third reader comprises determining if one of the first reader, the second reader, or the third reader provides readings that are different from the other two readers.': {'12': 0.08063919283598678,\n",
       "  '.': 0.027036117589752925,\n",
       "  'method': 0.015587693052787713,\n",
       "  'claim': 0.016701512788345328,\n",
       "  '11': 0.06558769305278771,\n",
       "  ',': 0.07793846526393856,\n",
       "  'wherein': 0.023332791052074874,\n",
       "  'check': 0.06558769305278771,\n",
       "  'perform': 0.06558769305278771,\n",
       "  'first': 0.06127838567197355,\n",
       "  'reader': 0.19998691004652863,\n",
       "  'second': 0.06127838567197355,\n",
       "  'third': 0.07676858167054787,\n",
       "  'compris': 0.016701512788345328,\n",
       "  'determin': 0.03292706736402053,\n",
       "  'one': 0.0354846934863896,\n",
       "  'provid': 0.08063919283598678,\n",
       "  'read': 0.03292706736402053,\n",
       "  'differ': 0.08063919283598678,\n",
       "  'two': 0.08063919283598678},\n",
       " '13. The method of claim 1, further comprising: varying the conditions for each of the first, second, and third readers, so that readings from each of the first, the second, and the third readers cover a range of conditions within predetermined thresholds.': {'13': 0.050536193269588664,\n",
       "  '.': 0.027036117589752925,\n",
       "  'method': 0.015587693052787713,\n",
       "  'claim': 0.016701512788345328,\n",
       "  '1': 0.038384290835273935,\n",
       "  ',': 0.09352615831672627,\n",
       "  'compris': 0.016701512788345328,\n",
       "  ':': 0.038384290835273935,\n",
       "  'vari': 0.050536193269588664,\n",
       "  'condit': 0.10107238653917733,\n",
       "  'first': 0.06127838567197355,\n",
       "  'second': 0.06127838567197355,\n",
       "  'third': 0.07676858167054787,\n",
       "  'reader': 0.05713911715615105,\n",
       "  'read': 0.03292706736402053,\n",
       "  'cover': 0.06558769305278771,\n",
       "  'rang': 0.06558769305278771,\n",
       "  'within': 0.050536193269588664,\n",
       "  'predetermin': 0.050536193269588664,\n",
       "  'threshold': 0.050536193269588664},\n",
       " '14. The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers.': {'14': 0.09486963863057267,\n",
       "  '.': 0.031807197164415206,\n",
       "  'method': 0.018338462415044367,\n",
       "  'claim': 0.019648838574523913,\n",
       "  '13': 0.05945434502304548,\n",
       "  ',': 0.07335384966017747,\n",
       "  'wherein': 0.02745034241420573,\n",
       "  'vari': 0.11890869004609096,\n",
       "  'condit': 0.11890869004609096,\n",
       "  'compris': 0.019648838574523913,\n",
       "  'least': 0.24548017833414465,\n",
       "  'one': 0.2087334910964094,\n",
       "  'age': 0.09486963863057267,\n",
       "  'reader': 0.13444498154388482,\n",
       "  'temperatur': 0.09486963863057267,\n",
       "  'construct': 0.09486963863057267,\n",
       "  'compon': 0.09486963863057267},\n",
       " '15. The method of claim 13, wherein varying the conditions comprises varying the conditions to cover the expected range of conditions for readers that will be used in the field.': {'15': 0.10079899104498347,\n",
       "  '.': 0.03379514698719115,\n",
       "  'method': 0.01948461631598464,\n",
       "  'claim': 0.02087689098543166,\n",
       "  '13': 0.06317024158698582,\n",
       "  ',': 0.01948461631598464,\n",
       "  'wherein': 0.02916598881509359,\n",
       "  'vari': 0.12634048317397165,\n",
       "  'condit': 0.18951072476095748,\n",
       "  'compris': 0.02087689098543166,\n",
       "  'cover': 0.08198461631598464,\n",
       "  'expect': 0.10079899104498347,\n",
       "  'rang': 0.08198461631598464,\n",
       "  'reader': 0.0357119482225944,\n",
       "  'use': 0.047980363544092415,\n",
       "  'field': 0.10079899104498347},\n",
       " '16. The method of claim 13, wherein varying the conditions comprises offsetting each of the first, second, and third readers from each other.': {'16': 0.08745025740371695,\n",
       "  '.': 0.03604815678633723,\n",
       "  'method': 0.020783590737050283,\n",
       "  'claim': 0.02226868371779377,\n",
       "  '13': 0.06738159102611821,\n",
       "  ',': 0.06235077221115085,\n",
       "  'wherein': 0.031110388069433163,\n",
       "  'vari': 0.06738159102611821,\n",
       "  'condit': 0.06738159102611821,\n",
       "  'compris': 0.02226868371779377,\n",
       "  'offset': 0.06738159102611821,\n",
       "  'first': 0.04085225711464903,\n",
       "  'second': 0.04085225711464903,\n",
       "  'third': 0.051179054447031906,\n",
       "  'reader': 0.038092744770767364},\n",
       " '17. The method of claim 16, wherein offsetting each of the first, second, and third readers from each other comprises offsetting each of the first, second, and third readers from each other by a constant offset.': {'17': 0.0811187572857195,\n",
       "  '.': 0.03862302512821846,\n",
       "  'method': 0.022268132932553874,\n",
       "  'claim': 0.023859303983350465,\n",
       "  '16': 0.09369670436112529,\n",
       "  ',': 0.11134066466276937,\n",
       "  'wherein': 0.03333255864582124,\n",
       "  'offset': 0.21658368544109424,\n",
       "  'first': 0.0875405509599622,\n",
       "  'second': 0.0875405509599622,\n",
       "  'third': 0.10966940238649694,\n",
       "  'reader': 0.08162731022307292,\n",
       "  'compris': 0.023859303983350465,\n",
       "  'constant': 0.0811187572857195},\n",
       " '18. The method of claim 17, further comprising using false acceptance rate and false rejection rate tolerances to determine the constant offset.': {'18': 0.10079899104498347,\n",
       "  '.': 0.03379514698719115,\n",
       "  'method': 0.01948461631598464,\n",
       "  'claim': 0.02087689098543166,\n",
       "  '17': 0.07097891262500457,\n",
       "  ',': 0.01948461631598464,\n",
       "  'compris': 0.02087689098543166,\n",
       "  'use': 0.047980363544092415,\n",
       "  'fals': 0.20159798208996693,\n",
       "  'accept': 0.044355866857986995,\n",
       "  'rate': 0.20159798208996693,\n",
       "  'reject': 0.057113365773982294,\n",
       "  'toler': 0.10079899104498347,\n",
       "  'determin': 0.04115883420502566,\n",
       "  'constant': 0.07097891262500457,\n",
       "  'offset': 0.06317024158698582},\n",
       " '19. The method of claim 17, further comprising using the constant offset to determine a minimum number of readers to be used.': {'19': 0.11519884690855253,\n",
       "  '.': 0.03862302512821846,\n",
       "  'method': 0.022268132932553874,\n",
       "  'claim': 0.023859303983350465,\n",
       "  '17': 0.0811187572857195,\n",
       "  ',': 0.022268132932553874,\n",
       "  'compris': 0.023859303983350465,\n",
       "  'use': 0.10966940238649694,\n",
       "  'constant': 0.0811187572857195,\n",
       "  'offset': 0.07219456181369809,\n",
       "  'determin': 0.04703866766288647,\n",
       "  'minimum': 0.11519884690855253,\n",
       "  'number': 0.11519884690855253,\n",
       "  'reader': 0.04081365511153646},\n",
       " '20-25.': {'20-25': 0.8063919283598677, '.': 0.1351805879487646},\n",
       " '(canceled) 26.': {'(': 0.3225567713439471,\n",
       "  'cancel': 0.3225567713439471,\n",
       "  ')': 0.3225567713439471,\n",
       "  '26': 0.3225567713439471,\n",
       "  '.': 0.05407223517950585},\n",
       " 'The method of claim 1, wherein the method is configured to read and verify the tag based on the inherent disorder function during a manufacturing process.': {'method': 0.036676924830088733,\n",
       "  'claim': 0.019648838574523913,\n",
       "  '1': 0.04515798921796933,\n",
       "  ',': 0.018338462415044367,\n",
       "  'wherein': 0.02745034241420573,\n",
       "  'configur': 0.09486963863057267,\n",
       "  'read': 0.03873772631061239,\n",
       "  'verifi': 0.09486963863057267,\n",
       "  'tag': 0.041746698219281876,\n",
       "  'base': 0.04515798921796933,\n",
       "  'inher': 0.05945434502304548,\n",
       "  'disord': 0.05945434502304548,\n",
       "  'function': 0.09486963863057267,\n",
       "  'dure': 0.09486963863057267,\n",
       "  'manufactur': 0.09486963863057267,\n",
       "  'process': 0.09486963863057267,\n",
       "  '.': 0.015903598582207603}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "sentenceValue= _score_sentences(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. A method comprising: using a first reader to take a first reading of an inherent disorder feature of a tag; using at least a second reader to take at least a second reading of the inherent disorder feature of the tag; matching the first reading with at least the second reading; determining one or more acceptance criteria, wherein at least one of the acceptance criteria is based on whether the first reading and the second reading match within a predetermined threshold; accepting the tag if the acceptance criteria are met; and recording a fingerprint for the tag if the tag was accepted.': 0.05323332989145503,\n",
       " '2. The method of claim 1, wherein determining one or more acceptance criteria further comprises: determining an acceptance criterion based on an individual reading.': 0.04541322207271596,\n",
       " '3. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a strength of a signal in at least one of the first reading and the second reading.': 0.05036600303633186,\n",
       " '4. The method of claim 2, wherein determining an acceptance criterion based on an individual reading comprises determining an acceptance criterion based on a complexity of a signal in at least one of the first reading and the second reading.': 0.05036600303633186,\n",
       " '5. The method of claim 1, further comprising: rejecting the tag if it is not accepted.': 0.056500218286700106,\n",
       " '6. The method of claim 5, wherein rejecting the tag comprises removing the tag without stopping the flow of production.': 0.065966461108052,\n",
       " '7. The method of claim 6, wherein removing the tag comprises one or more of marking the tag as rejected, cutting out the tag, punching out the tag, and removing a tag using a suction method.': 0.07434188790632106,\n",
       " '8. The method of claim 5, wherein rejecting the tag further comprises noting the rejected tag in a database.': 0.07999983349211232,\n",
       " '9. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag if the acceptance criteria are not met; matching the third reading with the first reading and the second reading; determining one or more further acceptance criteria, wherein at least one of the further acceptance criteria is based on whether the first reading and the third reading match within the predetermined threshold or whether the second reading and the third reading match within the predetermined threshold; and accepting the tag if the further acceptance criteria are met; and if the tag is accepted, recording a fingerprint for the tag based on the first reading if the first reading and the third reading match within the predetermined threshold or based on the second reading if the second reading and the third reading match within the predetermined threshold.': 0.06497189705017203,\n",
       " '10. The method of claim 1, further comprising: using at least a third reader to take at least a third reading of the inherent disorder feature of the tag; matching the third reading with the first reading and the second reading; determining an acceptance criterion based on whether the first reading and the third reading match within the predetermined threshold; and determining an acceptance criterion based on whether the second reading and the third reading match within the predetermined threshold.': 0.05076783797841055,\n",
       " '11. The method of claim 10, further comprising: checking the performance of the first reader, the second reader, and the third reader.': 0.06213227863933605,\n",
       " '12. The method of claim 11, wherein checking the performance of the first reader, the second reader, and the third reader comprises determining if one of the first reader, the second reader, or the third reader provides readings that are different from the other two readers.': 0.05986345171565046,\n",
       " '13. The method of claim 1, further comprising: varying the conditions for each of the first, second, and third readers, so that readings from each of the first, the second, and the third readers cover a range of conditions within predetermined thresholds.': 0.05103209263669341,\n",
       " '14. The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers.': 0.09120741753208356,\n",
       " '15. The method of claim 13, wherein varying the conditions comprises varying the conditions to cover the expected range of conditions for readers that will be used in the field.': 0.06704775734128993,\n",
       " '16. The method of claim 13, wherein varying the conditions comprises offsetting each of the first, second, and third readers from each other.': 0.04818554734632308,\n",
       " '17. The method of claim 16, wherein offsetting each of the first, second, and third readers from each other comprises offsetting each of the first, second, and third readers from each other by a constant offset.': 0.07801276487422974,\n",
       " '18. The method of claim 17, further comprising using false acceptance rate and false rejection rate tolerances to determine the constant offset.': 0.06969053781737544,\n",
       " '19. The method of claim 17, further comprising using the constant offset to determine a minimum number of readers to be used.': 0.06488773151655297,\n",
       " '20-25.': 0.4707862581543162,\n",
       " '(canceled) 26.': 0.26885986411105883,\n",
       " 'The method of claim 1, wherein the method is configured to read and verify the tag based on the inherent disorder function during a manufacturing process.': 0.05746735833008413}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "threshold = _find_average_score(sentenceValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09004998881243623"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:len(sentence)] in sentenceValue and sentenceValue[sentence[:len(sentence)]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the summary with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 14. The method of claim 13, wherein varying the conditions comprises varying at least one of the age of at least one of the readers, the temperature conditions for at least one of the readers, the construction of at least one of the readers, and the components of at least one of the readers. 20-25. (canceled) 26.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_generate_summary(combined_sentences, sentenceValue, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing Dependency Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
